
\chapter{Introduction}

\section{Definition of collocation}


Precise defining collocation is not a simple task. This problem was nicely illustrated by Choueka in Stefan Evert book 
\textit{"Even though any two lexicographers would agree that ’once upon a time’, ’hit the road’ and similar idioms are collocations,
they would most certainly disagree on almost anything else."}
Lexicographers argued over the years on correct defining what collocation is and because of that there is not one fixed definition of collocation  
and in relevant literature we can find many different versions but most of them have one common characteristic, 
collocation is a multiword expression that are syntactically and/or semantically idiomatic. Because this thesis will base on MeWeX system 
it assumes the same definition as in Michał Wendelberger thesis, for which purpose MeWeX was created.
\begin{quote}
    Collocation is a multiword specialistic term or noncompositional general term. 
    It may be both continous or not and both in fixed or flexible order.
    \cite{mgr}
    % Za wyrażenie wielowyrazowe uznawane są wieloelementowe terminy specjalistyczne oraz
    % niekompozycyjne terminy ogólne. Mogą być one zarówno ciągłe, w szyku przemiennym, jak i
    % ustalonym.
\end{quote}
This definition was motivated by similarity to others definitions used by lexicographers and it fits the needs for creating polish MWE "dictionary (lexicon)". 

\section{Methods for extraction of collocations} \label{extraction_method}
Automatic extraction of collocations is a very hard task. First of all precise specification of collocation is required.
Method of extraction is dependent on choosen definition of MWE but also on other factors like language. 
Even having precisly specified all conditions it may be performed in many different ways. 
Usually finding MWE is done in three steps. At first candidates for collocation are extracted from the text using some rules and filters, 
which most often base on grammar of given language. Second step is to evaluate quality of the candidates 
using some association measure or more sophisticated algorithms and sorting it according to obtained values. 
Finally collocations are choosen from generated ranking. Method used in MeWeX fits in mentioned above general way, 
more detailed description is included in section \ref{mewex_workflow}.

\section{MeWex}

\subsection{General description}
MeWeX is a system designed for extraction of collocations. It is designed as a set of separate programs 
that preforms consequitive parts of extraction process, but it can be also used as a "programmatic" library in other projects. 
This design gives huge flexibility, because it allows to run given part many times in different setup, 
or to preprocess large data and save result of every step. This capabilities are very useful in conducting reaserch. 
It is also helpful in natural language processing where often size of data is very large, so possibility 
to preprocess input once and repeating further stages many times with different setup can save a lot of time.

\subsection{Structure of the program}
MeWeX has a lot functionalities, so to preserve clear and maintainable code it has expanded stucture. 
This also simplify further extensions and modifications of the system. Schema of code structure of more important 
or significant for this thesis parts of MeWeX is presented on figure \ref{img_structure}.

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.5]{img/mewex_structure.png}
	\caption{Code structure of MeWeX}
	\label{img_structure}
\end{figure}

All functionalities are provided as a set of programs that together creates complete tool for collocation extraction,
verification of the results, tunning weigths, result analysis etc. Below there is a list of all of them together with short description.
\begin{itemize}
    \item \textbf{TuplesBuilder} - Program that reads corpora given as an input and using wccl operators given in input file 
    it creates candidates for collocations.
 
    \item \textbf{Continger} - It creates generators of contingency tables from tuples built by TuplesBuilder.
 
    \item \textbf{Indexer} - This program uses contingency table generators to create set of contingency tables.
 
    \item \textbf{Normalizer} - Program that performs dispersion on contingency tables.
 
    \item \textbf{FeatureMaker} - This program prepares feature vector by evaluating association measures specified at input for each tuple. 
    using output of this program we can train weights for aggregators in reasonable time.
 
    \item \textbf{Heuristic} - It uses given machine learning algorithm to tune weights for association measures. 
    This process is highly adjustable, all parameters for training can be specified in config file.
 
    \item \textbf{Digger} - This program extract collocations basing on given association measures or vector of them. 
    It also provide functionality of extracting encountered forms of collocations.
 
    \item \textbf{Miner} - Program created to perform f-fold cross validation for choosen association measures or classifiers.
    
    \item \textbf{Cover} - It examines coverage of extracted collocations in relations set. It also creates matrix 
    that shows intersection of extracted tuples between relations. It allows to check how many tuples was assigned to more than one relation 
    and which are the most frequent.
 
    \item \textbf{Judger} - This program evaluates results of extracted collocations. It calculates the percentage of correct MWE.
 
    \item \textbf{Reductor} - This program reduces the number of false candidates from set of all tuples created from the text. 
    Ratio of true to false candidates can be specified in parameter.
 
    \item \textbf{WebTool} - Complex tool that performs whole process of extraction at once, starting from plain text 
    it returns list of extracted collocations.
 
    \item \textbf{Teacher} - Program that can be used for training neural network or support vector machine.
 
    
\end{itemize}

\subsection{Workflow of the program} \label{mewex_workflow}
As functionalities of MeWeX are splitted between many separate programs, usually to achive some result several programs must be run in specific order. 
This design, to construct different chains of programs, extends set of possibilities. Some exemplary workflow of the system are described below. 
\\ \textbf{Workflow for evaluation of efficiency of methods for extraction of collocations}
\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.4]{img/mewex_workflow1.png}
	\caption{Examplary workflow}
	\label{img_workflow1}
\end{figure}
\\ Figure \ref{img_workflow1} shows schema of typical path for evaluation of efficiency of given association measure or classifier.
\\ \textbf{Step 1: Tuples generating}\\
First step is to generate tuples from text using WCCL operators, which determine what groups of words are selected for candidates. 
To preform that step program TuplesBuilder is used. It requires list of corpora, corpus reader and name of tagset and 
set of mentioned before wccl operators. Output of this program is CSV file with one tuple per line, consisting information about relation, 
its name, group and size and also all elements of tuple.
\\ \textbf{Step 2: Normalization}\\
Second step is optional and allows modification of information about tuples using one of availble dispersion function. 
It may be useful for processing many corpora of differentiated categories, because it changes frequency distribution of tuples 
favouring less common candidates.
\\ \textbf{Step 3: Evaluation}\\
Final step is to perform f-fold, r-round cross-validation for given dataset. Program accepts as an input many parameters, 
so they are described in table \ref{tbl_workflow1}. After processing it returns 2 sets of files. First type contains k-best list 
of candidates for every fold in every round for every measure and second includes evaluation of those lists. 
Those files should be further analized by the user. 

\begin{table}[t]
    \centering
    % \begin{tabular}{|l|l|}
    \begin{tabular*}{\textwidth}{|l @{\extracolsep{\fill}} l|}
        \hline 
        \textbf{Name of parameter} & \textbf{Description} \\
        \hline
        Tuple storage & Name of the folder with generated tuples \\
        \hline
        Output & Path to the folder were output will be placed \\
        \hline
        Association Measure & Name of association measure to use, \\& this can be specified many times \\
        \hline
        Vector association measure & Text representing vector association measure \\
        \hline
        Aggregator & Aggregator fuction for vector association measure \\
        \hline
        Classifier & Text representing classifier which has to be used \\
        \hline
        Feature generator & Vector association measure which will be used \\& for generating features for classifier \\
        \hline
        Feature preprocessor & Text representing function which has to be used \\& to normalze features for classifier \\
        \hline
        Relevant set & File containing proper MWE, one in line \\
        \hline
        Quality function & Text representing function for evaluation of quality \\& of extracted collocations \\
        \hline
        Tuple filter & Filter that is used to reduce number of tuples \\
        \hline
        Thread number & Maximal number of threads used by program \\
        \hline
        Number of folds & Number of folds for cross-validation \\
        \hline
        Number of rounds & Number of rounds for cross-validation \\
        \hline
    \end{tabular*} 
    \caption{Input parameters for program Miner}
    \label{tbl_workflow1}
\end{table}

\noindent \textbf{Workflow for extraction of collocations}
\\ Figure \ref{img_workflow2} shows schema of typical path for extraction of MWEs using given association measure or classifier.
Steps 1 and 2 are identical as in previous example, so they will not be described again.
\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.4]{img/mewex_workflow2.png}
	\caption{Examplary workflow}
	\label{img_workflow2}
\end{figure}
\\ \textbf{Step 3: Building contingency table}\\
All measures needs statistical data contained in contingency tables, so they must be generated for further process. 
There are two ways of creating that tables. First is to use Continger, which prepares source of contingency tables, 
this solution uses less memory, but it is more time-consuming. Second way is to use Indexer which generates storage of contingency tables, 
that consumes more memory, but further using those tables requires less time.
\\ \textbf{Step 4: Creating features set}\\
Next step is to prepare features set. This is done be calculating results of all specified association measures for all tuples. 
Those scores will be further used by classifiers or aggregators.
\\ \textbf{Step 5: Extraction}\\
Final step is perform extraction of collocations. This step is performed by program Digger. Input parameters are described 
in table \ref{tbl_workflow1}. Output of this program is similar as in previous case, but this time there are only two files, 
one with k-best list and second includes quality evaluation of this lists, because no cross-validation is performed.

\begin{table}[t]
    \centering
    \begin{tabular*}{\textwidth}{|l @{\extracolsep{\fill}} l|}
        \hline 
        \textbf{Name of parameter} & \textbf{Description} \\
        \hline
        Tuple storage & Name of the folder with generated tuples \\
        \hline
        Contingency tables & Path to file with contingency table source or storage \\
        \hline
        Output & Path to the folder were output will be placed \\
        \hline
        Association Measure & Name of association measure to use, \\& this can be specified many times \\
        \hline
        Vector association measure & Text representing vector association measure \\
        \hline
        Aggregator & Aggregator fuction for vector association measure \\
        \hline
        Classifier & Text representing classifier which has to be used \\
        \hline
        Features set & Path to file with calculated set of features \\
        \hline
        Relevant set & File containing proper MWE, one in line \\
        \hline
        Quality function & Text representing function for evaluation of quality \\& of extracted collocations \\
        \hline
        Tuple filter & Filter that is used to reduce number of tuples \\
        \hline
        Thread number & Maximal number of threads used by program \\
        \hline
    \end{tabular*} 
    \caption{Input parameters for program Digger}
    \label{tbl_workflow2}
\end{table}

\section{Scope of the thesis}

\subsection{General}
Purpose of this thesis is to improve efficiency of the MeWeX. Due to complexity of this system this task 
will consist of few parts listed in sections below.

\subsection{Test association measure functions}
First step is to perform unit test of association measures implementation. Author of the MeWeX did not prepared unit test for this part, 
so there is possibility, that those functions are incorrectly implemented. Errors generated on this stage will propagate in following data process, 
so it can preclude improving further stages. That way it is important to start with checking correctness of the implementation 
at the beggining.

\subsection{Implement new association measure}
MeWeX was implemented in 2014 and natural language processing is a branch of science developing rapidly nowadays, 
so from that time new association measures may were invented. Task for the author of this tesis is to carefully examine recently written literature 
in search of newly proposed association measures which would be suitable for rating MWE. If some measure will satisfy those condition it should 
be implemented and the last step would be to verify efficiency of that measure.

\subsection{Imlement algorithm for training weigths for vector association measure}
In MeWeX we can evaluate candidates for collocation using not only single association measure, but also aggregated score from more than one measure. 
In that case vector of measures is created and each measure has assigned weigth. Currently in MeWeX there are implemented few simple algorithms 
based on machine learning which trains vector of weigths. For purpose of this thesis new algorithm should be found and implemented.

\subsection{Train classifier on new data}
Mentioned section above algorithms for training weigths needs proper training data. This includes corpora of polish texts and set 
of proper collocations. Michał Wendelberger while working on MeWeX had quite large corpora, but insufficient set of correct MWE limited his results. 
Now in polish Wordnet there is availble much bigger set of collocations. Many of them was gathered with use of MeWeX.
Using new, more copmplete, dataset weigths for aggregators should be retrained in order to obtain better results.

\subsection{Compare new results with previous one}
Last step is to compare results achived by improved version with score that author of MeWeX achieved in his thesis.
To do that, some of the examinations conducted in thesis by Michał Wendelberger will be repeated with new implemented or improved features. 
Only part of experiments will be conducted again, because scope of this thesis does not cover all functionalities offered by MeWeX.